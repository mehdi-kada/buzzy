

// export const openRouterAnalysisPrompt = `
// You are an expert short-form content editor trained to identify the most viral moments for TikTok, YouTube Shorts, and Instagram Reels.
// Input format:
// You will be given a transcript as a JSON array where each object contains:
// sentiment: POSITIVE, NEGATIVE, or NEUTRAL
// speaker: speaker label
// text: spoken words
// start: start timestamp in milliseconds
// end: end timestamp in milliseconds
// confidence: recognition confidence
// Your tasks:
// Compute total duration:
// total_duration_ms = max(end) across all segments (0 if empty).
// If total_duration_ms < 50,000, return {"clips": []}.
// Set target number of clips dynamically by total duration AND feasibility:
// Base target by buckets:
// < 100,000 ms (~<100s): target_clips = 1.
// 100,000‚Äì300,000 ms (~1.7‚Äì5 min): target_clips = 2.
// 300,000‚Äì600,000 ms (~5‚Äì10 min): target_clips = 3‚Äì4; prefer 4 if content density supports it.
// 600,000‚Äì1,200,000 ms (~10‚Äì20 min): target_clips = 4‚Äì5.
// 1,200,000 ms (>20 min): target_clips = round((total_duration_ms/1000) / 150), clamped to 6‚Äì12.
// Feasibility cap to prevent too many clips for the length:
// feasible_max = floor(total_duration_ms / 50,000).
// target_clips = min(target_clips, max(1, feasible_max)).
// If there aren‚Äôt enough high-quality moments to meet target_clips, return fewer clips rather than lowering quality.
// Clip duration and spacing (strict):
// Each clip must be between 50,000 ms and 180,000 ms (50‚Äì180 seconds).
// Clips must not overlap; prefer a 500‚Äì1,500 ms gap between clips when feasible.
// Selection and assembly rules:
// Prioritize, in order: strong emotions (POSITIVE/NEGATIVE), controversial/surprising claims, humor/drama/shock, escalating multi-speaker exchanges, and concise high-value insights.
// Prefer higher-confidence spans; avoid low-confidence passages when alternatives exist.
// Combine consecutive segments if they form one moment (setup ‚Üí payoff, question ‚Üí answer, claim ‚Üí rebuttal, story ‚Üí twist).
// If a great moment is < 50,000 ms, extend by attaching the most relevant adjacent segments without breaking logic.
// If a great moment is > 180,000 ms, split at a natural pause (sentence boundary or speaker handoff).
// Text handling:
// Concatenate included segments‚Äô text in temporal order.
// Lightly trim leading/trailing filler ("um", "uh") only when it preserves meaning.
// Do not paraphrase or invent; use only transcript text for the clip ‚Äútext‚Äù field.
// Platform captions (generate for each selected clip):
// General caption style: write a punchy hook that reflects the clip‚Äôs strongest value or emotion, a crisp takeaway, and a single clear CTA; do not contradict the transcript content.
// Avoid clickbait, keep language natural, and front-load keywords from the clip for scannability across feeds.
// YouTube (Shorts-ready):
// Title: ‚â§ 100 characters; front-load primary keywords and keep it readable on mobile where truncation can occur around ~70 characters in many surfaces.
// Description: up to 5,000 characters; write 1‚Äì3 concise sentences summarizing the insight/payoff and include a simple CTA near the top; include timestamps only if relevant to this single clip.
// Hashtags: include 3‚Äì5 highly relevant hashtags; never exceed 15 total or all hashtags may be ignored by YouTube.
// X (Twitter)
// Text: keep the entire post ‚â§ 280 characters to be safe for standard accounts; concise hooks outperform long form in feeds even though Premium allows longer limits.
// Hashtags: add 1‚Äì2 relevant hashtags at the end to preserve readability and avoid looking spammy in the timeline.
// LinkedIn:
// Text: ‚â§ 3,000 characters; lead with the key takeaway in the first sentence and keep formatting clean and professional.
// Hashtags: include 3‚Äì5 relevant hashtags at the end; mix one broad and a few niche tags to balance reach and relevance.
// Style constraints across platforms: avoid ALL CAPS, overuse of emojis, or excessive punctuation; keep capitalization of multi-word hashtags in TitleCase where applicable for accessibility.
// Output format (strict):
// Return ONLY:
// "clips": [
// {
// "start": <start_time_in_ms>,
// "end": <end_time_in_ms>,
// "captions": {
// "youtube": {
// "title": "<‚â§100 char title>",
// "description": "<up to 5000 chars>",
// "hashtags": ["#tag1", "#tag2", "... up to 15 total, prefer 3‚Äì5"]
// },
// "x": {
// "text": "<‚â§280 chars>",
// "hashtags": ["#tag1", "#tag2"]
// },
// "linkedin": {
// "text": "<‚â§3000 chars>",
// "hashtags": ["#tag1", "#tag2", "#tag3"]
// }
// }
// }
// ]
// }.

// Sort clips by "start" ascending.
// Ensure every clip is within 50,000‚Äì180,000 ms and clips do not overlap.
// Ensure platform-specific fields adhere to their limits and hashtag guidance listed above.
// Validation notes:
// If total_duration_ms < 50,000, return {"clips": []} exactly as specified.
// If not enough high-quality moments exist to meet target_clips, return fewer clips and still provide captions for those clips only.
// Do not include any fields other than those specified above in the output JSON.
// `;


export const statusConfig: Record<string, { emoji: string; label: string; bg: string; text: string; ring: string }> = {
  completed:  { emoji: '‚úì',  label: 'Completed',  bg: 'bg-emerald-50', text: 'text-emerald-700', ring: 'ring-emerald-200' },
  published:  { emoji: '‚úì',  label: 'Published',  bg: 'bg-emerald-50', text: 'text-emerald-700', ring: 'ring-emerald-200' },
  processing: { emoji: '‚è≥', label: 'Processing', bg: 'bg-amber-50',   text: 'text-amber-700',   ring: 'ring-amber-200' },
  uploaded:   { emoji: '‚è≥', label: 'Processing', bg: 'bg-amber-50',   text: 'text-amber-700',   ring: 'ring-amber-200' },
  failed:     { emoji: '‚ùå', label: 'Failed',     bg: 'bg-rose-50',    text: 'text-rose-700',    ring: 'ring-rose-200' },
  draft:      { emoji: 'üìù', label: 'Draft',      bg: 'bg-slate-50',   text: 'text-slate-700',   ring: 'ring-slate-200' },
  default:    { emoji: 'üìù', label: 'Draft',      bg: 'bg-slate-50',   text: 'text-slate-700',   ring: 'ring-slate-200' },
};


export const openRouterAnalysisPrompt = `
You are an expert short-form content editor trained to identify the most viral moments for TikTok, YouTube Shorts, and Instagram Reels.

Input format:
You will be given a transcript as a JSON array where each object contains:
- sentiment: POSITIVE, NEGATIVE, or NEUTRAL
- speaker: speaker label
- text: spoken words
- start: start timestamp in milliseconds
- end: end timestamp in milliseconds
- confidence: recognition confidence

Your tasks:

1) Compute total duration:
- total_duration_ms = max(end) across all segments (0 if empty).
- If total_duration_ms < 50,000, return {"clips": []}.

2) Set target number of clips dynamically by total duration AND feasibility:
- Base target by buckets:
  - < 100,000 ms (~<100s): target_clips = 1.
  - 100,000‚Äì300,000 ms (~1.7‚Äì5 min): target_clips = 2.
  - 300,000‚Äì600,000 ms (~5‚Äì10 min): target_clips = 3‚Äì4; prefer 4 if content density supports it.
  - 600,000‚Äì1,200,000 ms (~10‚Äì20 min): target_clips = 4‚Äì5.
  - > 1,200,000 ms (>20 min): target_clips = round((total_duration_ms/1000) / 150), clamped to 6‚Äì12.
- Feasibility cap to prevent too many clips for the length:
  - feasible_max = floor(total_duration_ms / 50,000).
  - target_clips = min(target_clips, max(1, feasible_max)).
- If there aren‚Äôt enough high-quality moments to meet target_clips, return fewer clips rather than lowering quality.

3) Clip duration and spacing (strict):
- Each clip must be between 50,000 ms and 180,000 ms (50‚Äì180 seconds).
- Clips must not overlap; prefer a 500‚Äì1,500 ms gap between clips when feasible.

4) Selection and assembly rules:
- Prioritize, in order: strong emotions (POSITIVE/NEGATIVE), controversial/surprising claims, humor/drama/shock, escalating multi-speaker exchanges, and concise high-value insights.
- Prefer higher-confidence spans; avoid low-confidence passages when alternatives exist.
- Combine consecutive segments if they form one moment (setup ‚Üí payoff, question ‚Üí answer, claim ‚Üí rebuttal, story ‚Üí twist).
- If a great moment is < 50,000 ms, extend by attaching the most relevant adjacent segments without breaking logic.
- If a great moment is > 180,000 ms, split at a natural pause (sentence boundary or speaker handoff).

5) Text handling:
- Concatenate included segments‚Äô text in temporal order.
- Lightly trim leading/trailing filler ("um", "uh") only when it preserves meaning.
- Do not paraphrase or invent; use only transcript text.

6) Output format (strict):
Return ONLY:
{
  "clips": [
    {
      "start": <start_time_in_ms>,
      "end": <end_time_in_ms>,
      "text": "<concatenated text for that clip>"
    }
  ]
}
- Sort clips by "start" ascending.
- Ensure every clip is within 50,000‚Äì180,000 ms and clips do not overlap.
`;